{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc76303",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.compat.v1 import keras as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a080fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the root directory containing student subdirectories\n",
    "root_directory = \"C:/Users/HP/OneDrive/Documents/Photos\"\n",
    "\n",
    "# Initialize lists to store data\n",
    "data = []\n",
    "labels = []\n",
    "common_size = (224, 224)  # Adjust the size as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each subdirectory (student)\n",
    "for student_name in os.listdir(root_directory):\n",
    "    student_directory = os.path.join(root_directory, student_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(student_directory):\n",
    "        # Iterate through each image file in the student's directory\n",
    "        for image_file in os.listdir(student_directory):\n",
    "            image_path = os.path.join(student_directory, image_file)\n",
    "            \n",
    "            # Read the image using OpenCV\n",
    "            img = cv2.imread(image_path)\n",
    "            img_resized = cv2.resize(img, common_size)\n",
    "            \n",
    "            # Append the resized image and label to the data lists\n",
    "            data.append(img_resized)\n",
    "            labels.append(student_name)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2de8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the data and labels arrays\n",
    "print(\"Data shape:\", data.shape)\n",
    "print(\"Labels shape:\", labels.shape)\n",
    "print(np.unique(labels))\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "labels_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c30c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use data augmentation\n",
    "datagen_train = ImageDataGenerator(\n",
    "    rotation_range=20,       \n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets with stratified sampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42, stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21175865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "base_model = applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # Change 1 to 3 for RGB\n",
    "# Freeze the weights of the pre-trained layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb6a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(len(np.unique(labels)), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509c172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b21ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43ca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with data augmentation\n",
    "# Convert string labels to numerical format\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "train_generator = datagen_train.flow(X_train, y_train_encoded, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7b6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=50, validation_data=(X_test, y_test_encoded), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d914681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set using data generator\n",
    "test_generator = datagen_train.flow(X_test, y_test_encoded, batch_size=64)\n",
    "accuracy = model.evaluate(test_generator)[1]\n",
    "print(\"Test Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38f8789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and validation loss over epochs\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7bea3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# Initialize attendance_df outside the function\n",
    "attendance_df = pd.DataFrame(columns=['Name', 'Time', 'Date'])\n",
    "\n",
    "# Initialize a buffer for smoothing predicted labels\n",
    "label_buffer = []\n",
    "\n",
    "# Initialize temp as a global variable\n",
    "global temp\n",
    "temp = 0\n",
    "\n",
    "def mark_attendance(predictions):\n",
    "    global attendance_df, temp\n",
    "    \n",
    "    # Check if the label buffer is empty\n",
    "    if not label_buffer:\n",
    "        return\n",
    "\n",
    "    # Apply label smoothing and get the final prediction\n",
    "    final_prediction = max(set(label_buffer), key=label_buffer.count)\n",
    "    print(f\"final prediction: {final_prediction}\")\n",
    "    # Use the mode of the labels in the buffer as the final prediction\n",
    "    if final_prediction in attendance_df['Name'].values:\n",
    "        return\n",
    "\n",
    "    # Check if the maximum confidence is above the threshold\n",
    "    confidence_threshold = 0.5  # Set your confidence threshold\n",
    "    if np.max(predictions) > confidence_threshold:\n",
    "        temp += 1\n",
    "        # Add to attendance DataFrame\n",
    "        now = datetime.now()\n",
    "        current_time = now.strftime('%I:%M:%S %p')\n",
    "        current_date = now.strftime('%d-%B-%Y')\n",
    "        new_record = pd.DataFrame({'Name': [predicted_name], 'Time': [current_time], 'Date': [current_date]})\n",
    "        attendance_df = pd.concat([attendance_df, new_record], ignore_index=True)\n",
    "\n",
    "        print(f\"Attendance marked for {predicted_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e00bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "try:\n",
    "    while True:\n",
    "        # Open the camera\n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        # Capture one photo\n",
    "        ret, frame = cap.read()\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect faces in the frame\n",
    "        faces = face_cascade.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY), scaleFactor=2, minNeighbors=2)\n",
    "\n",
    "        if len(faces) > 0:\n",
    "            # Extract the first face\n",
    "            x, y, w, h = faces[0]\n",
    "            face_roi = rgb_frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Resize the face image to match the model input size\n",
    "            face_resized = cv2.resize(face_roi, (224, 224))\n",
    "\n",
    "            # Normalize the pixel values\n",
    "            face_resized = face_resized / 255.0\n",
    "\n",
    "            # Reshape the image to match the model's expected shape\n",
    "            face_resized = np.reshape(face_resized, (1, 224, 224, 3))\n",
    "\n",
    "            # Make predictions using the model\n",
    "            predictions = model.predict(face_resized)\n",
    "            predicted_label = np.argmax(predictions)\n",
    "            label_buffer.append(predicted_label)\n",
    "            # Get the name associated with the predicted label\n",
    "            predicted_name = label_encoder.inverse_transform([predicted_label])[0]\n",
    "            print(f\"predicted face is {predicted_name}\")\n",
    "            # Draw a green rectangle around the face\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Display the name below the face\n",
    "            cv2.putText(frame, predicted_name, (x, y+h+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            # Display the frame\n",
    "            cv2.imshow('Face Recognition', frame)\n",
    "            # Wait for user input\n",
    "            key = cv2.waitKey(1)\n",
    "\n",
    "            # If the key pressed is 's', add to attendance\n",
    "            if key == ord('s'):\n",
    "               # Mark attendance based on user input\n",
    "                mark_attendance(predictions)\n",
    "            elif key == ord('q'):\n",
    "                cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    # Close all OpenCV windows\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38667d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attendance_df.head()\n",
    "attendance_df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
